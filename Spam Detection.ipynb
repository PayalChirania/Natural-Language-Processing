{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spam Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the spam detection problem, there are 2 classes: C1 which is the no-spam (ham) class and C2 which is the spam class. \n",
    "# X is essentially each email present in the training data. \n",
    "# To convert X into a machine-readable form (number), we basically need to convert X into a vector. \n",
    "# We achieve it by the following way:\n",
    "\n",
    "# Create an ordered list of all the words in the vocabulary. \n",
    "# For instance, suppose we have the following words in the vocabulary: [lottery, how, won, offer, thanks, the, you].\n",
    "# To convert an email into a vector, map out the number of times each word occurs in that email. \n",
    "# For instance, consider the following email: you won the lottery. \n",
    "# The vector form of the above email would be [1, 0, 1, 0, 0, 1, 1].\n",
    "\n",
    "# Now that we have mapped each email into a vector, we can apply the Naive Bayes algorithm on the data. \n",
    "# Observe that in the above process, we assumed that each word is produced independent of each other \n",
    "# and we discarded the ordering of words in the email. \n",
    "# This exactly is the “Naive” assumption and that’s how we plan to apply the Naive Bayes algorithm to this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2 Unnamed: 2  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Any results you write to the current directory are saved as output.\n",
    "data = pd.read_csv('spam.csv',encoding='latin-1')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  class                                               text\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop([\"Unnamed: 2\", \"Unnamed: 3\", \"Unnamed: 4\"], axis=1)\n",
    "data = data.rename(columns={\"v1\":\"class\", \"v2\":\"text\"})\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  class                                               text  length\n",
       "0   ham  Go until jurong point, crazy.. Available only ...     111\n",
       "1   ham                      Ok lar... Joking wif u oni...      29\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...     155\n",
       "3   ham  U dun say so early hor... U c already then say...      49\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...      61"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['length'] = data['text'].apply(len)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the length of each text messages to see whether it is correlated with the text classified as a spam or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(text):\n",
    "    \n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = [word for word in text.split() if word.lower() not in stopwords.words('english')]\n",
    "    words = \"\"\n",
    "    for i in text:\n",
    "            stemmer = SnowballStemmer(\"english\")\n",
    "            words += (stemmer.stem(i))+\" \"\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "textFeatures = data['text'].copy()\n",
    "textFeatures = textFeatures.apply(pre_process)\n",
    "vectorizer = TfidfVectorizer(\"english\")\n",
    "features = vectorizer.fit_transform(textFeatures)\n",
    "\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, data['class'], test_size=0.3, random_state=111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9850478468899522"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "mnb = MultinomialNB(alpha=0.2)\n",
    "mnb.fit(features_train, labels_train)\n",
    "prediction = mnb.predict(features_test)\n",
    "accuracy_score(labels_test,prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1429   11]\n",
      " [  14  218]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(labels_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       spam       0.99      0.99      0.99      1440\n",
      "        ham       0.95      0.94      0.95       232\n",
      "\n",
      "avg / total       0.98      0.99      0.99      1672\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "target_names = ['spam', 'ham']\n",
    "print(classification_report(labels_test, prediction, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Machine Learning Classifiers: Explore Random Forest model with grid-search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build our own Grid-search\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_RF(n_est, depth):\n",
    "    rf = RandomForestClassifier(n_estimators=n_est, max_depth=depth, n_jobs=-1)\n",
    "    rf_model = rf.fit(features_train, labels_train)\n",
    "    labels_pred = rf_model.predict(features_test)\n",
    "    precision, recall, fscore, support = score(labels_test, labels_pred, pos_label='spam', average='binary')\n",
    "    print('Est: {} / Depth: {} ---- Precision: {} / Recall: {} / Accuracy: {}'.format(\n",
    "        n_est, depth, round(precision, 3), round(recall, 3),\n",
    "        round((labels_pred==labels_test).sum() / len(labels_pred), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Est: 10 / Depth: 10 ---- Precision: 1.0 / Recall: 0.276 / Accuracy: 0.9\n",
      "Est: 10 / Depth: 20 ---- Precision: 1.0 / Recall: 0.491 / Accuracy: 0.929\n",
      "Est: 10 / Depth: 30 ---- Precision: 1.0 / Recall: 0.634 / Accuracy: 0.949\n",
      "Est: 10 / Depth: None ---- Precision: 0.979 / Recall: 0.797 / Accuracy: 0.969\n",
      "Est: 50 / Depth: 10 ---- Precision: 1.0 / Recall: 0.147 / Accuracy: 0.882\n",
      "Est: 50 / Depth: 20 ---- Precision: 1.0 / Recall: 0.534 / Accuracy: 0.935\n",
      "Est: 50 / Depth: 30 ---- Precision: 1.0 / Recall: 0.69 / Accuracy: 0.957\n",
      "Est: 50 / Depth: None ---- Precision: 1.0 / Recall: 0.828 / Accuracy: 0.976\n",
      "Est: 100 / Depth: 10 ---- Precision: 1.0 / Recall: 0.22 / Accuracy: 0.892\n",
      "Est: 100 / Depth: 20 ---- Precision: 1.0 / Recall: 0.504 / Accuracy: 0.931\n",
      "Est: 100 / Depth: 30 ---- Precision: 1.0 / Recall: 0.69 / Accuracy: 0.957\n",
      "Est: 100 / Depth: None ---- Precision: 1.0 / Recall: 0.828 / Accuracy: 0.976\n"
     ]
    }
   ],
   "source": [
    "for n_est in [10, 50, 100]:\n",
    "    for depth in [10, 20, 30, None]:\n",
    "        train_RF(n_est, depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Machine Learning Classifiers: Explore Gradient Boosting model with grid-search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_SUPPORTED_LOSS', '__abstractmethods__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_abc_cache', '_abc_negative_cache', '_abc_negative_cache_version', '_abc_registry', '_check_initialized', '_check_params', '_clear_state', '_decision_function', '_estimator_type', '_fit_stage', '_fit_stages', '_get_param_names', '_init_decision_function', '_init_state', '_is_initialized', '_make_estimator', '_resize_state', '_staged_decision_function', '_validate_estimator', '_validate_y', 'apply', 'decision_function', 'feature_importances_', 'fit', 'get_params', 'n_features', 'predict', 'predict_log_proba', 'predict_proba', 'score', 'set_params', 'staged_decision_function', 'staged_predict', 'staged_predict_proba']\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "print(dir(GradientBoostingClassifier))\n",
    "print(GradientBoostingClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_GB(est, max_depth, lr):\n",
    "    gb = GradientBoostingClassifier(n_estimators=est, max_depth=max_depth, learning_rate=lr)\n",
    "    gb_model = gb.fit(features_train, labels_train)\n",
    "    labels_pred = gb_model.predict(features_test)\n",
    "    precision, recall, fscore, train_support = score(labels_test, labels_pred, pos_label='spam', average='binary')\n",
    "    print('Est: {} / Depth: {} / LR: {} ---- Precision: {} / Recall: {} / Accuracy: {}'.format(\n",
    "        est, max_depth, lr, round(precision, 3), round(recall, 3), \n",
    "        round((labels_pred==labels_test).sum()/len(labels_pred), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\payal\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Est: 50 / Depth: 3 / LR: 0.01 ---- Precision: 0.0 / Recall: 0.0 / Accuracy: 0.861\n",
      "Est: 50 / Depth: 3 / LR: 0.1 ---- Precision: 0.958 / Recall: 0.685 / Accuracy: 0.952\n",
      "Est: 50 / Depth: 3 / LR: 1 ---- Precision: 0.877 / Recall: 0.797 / Accuracy: 0.956\n",
      "Est: 50 / Depth: 7 / LR: 0.01 ---- Precision: 1.0 / Recall: 0.017 / Accuracy: 0.864\n",
      "Est: 50 / Depth: 7 / LR: 0.1 ---- Precision: 0.895 / Recall: 0.806 / Accuracy: 0.96\n",
      "Est: 50 / Depth: 7 / LR: 1 ---- Precision: 0.885 / Recall: 0.832 / Accuracy: 0.962\n",
      "Est: 50 / Depth: 11 / LR: 0.01 ---- Precision: 1.0 / Recall: 0.004 / Accuracy: 0.862\n",
      "Est: 50 / Depth: 11 / LR: 0.1 ---- Precision: 0.887 / Recall: 0.815 / Accuracy: 0.96\n",
      "Est: 50 / Depth: 11 / LR: 1 ---- Precision: 0.9 / Recall: 0.819 / Accuracy: 0.962\n",
      "Est: 50 / Depth: 15 / LR: 0.01 ---- Precision: 1.0 / Recall: 0.004 / Accuracy: 0.862\n",
      "Est: 50 / Depth: 15 / LR: 0.1 ---- Precision: 0.913 / Recall: 0.819 / Accuracy: 0.964\n",
      "Est: 50 / Depth: 15 / LR: 1 ---- Precision: 0.87 / Recall: 0.81 / Accuracy: 0.957\n",
      "Est: 100 / Depth: 3 / LR: 0.01 ---- Precision: 0.933 / Recall: 0.362 / Accuracy: 0.908\n",
      "Est: 100 / Depth: 3 / LR: 0.1 ---- Precision: 0.958 / Recall: 0.789 / Accuracy: 0.966\n",
      "Est: 100 / Depth: 3 / LR: 1 ---- Precision: 0.894 / Recall: 0.802 / Accuracy: 0.959\n",
      "Est: 100 / Depth: 7 / LR: 0.01 ---- Precision: 0.913 / Recall: 0.591 / Accuracy: 0.935\n",
      "Est: 100 / Depth: 7 / LR: 0.1 ---- Precision: 0.91 / Recall: 0.832 / Accuracy: 0.965\n",
      "Est: 100 / Depth: 7 / LR: 1 ---- Precision: 0.866 / Recall: 0.78 / Accuracy: 0.953\n",
      "Est: 100 / Depth: 11 / LR: 0.01 ---- Precision: 0.903 / Recall: 0.681 / Accuracy: 0.946\n",
      "Est: 100 / Depth: 11 / LR: 0.1 ---- Precision: 0.901 / Recall: 0.828 / Accuracy: 0.964\n",
      "Est: 100 / Depth: 11 / LR: 1 ---- Precision: 0.869 / Recall: 0.832 / Accuracy: 0.959\n",
      "Est: 100 / Depth: 15 / LR: 0.01 ---- Precision: 0.914 / Recall: 0.733 / Accuracy: 0.953\n",
      "Est: 100 / Depth: 15 / LR: 0.1 ---- Precision: 0.907 / Recall: 0.836 / Accuracy: 0.965\n",
      "Est: 100 / Depth: 15 / LR: 1 ---- Precision: 0.877 / Recall: 0.828 / Accuracy: 0.96\n",
      "Est: 150 / Depth: 3 / LR: 0.01 ---- Precision: 0.919 / Recall: 0.534 / Accuracy: 0.929\n",
      "Est: 150 / Depth: 3 / LR: 0.1 ---- Precision: 0.96 / Recall: 0.819 / Accuracy: 0.97\n",
      "Est: 150 / Depth: 3 / LR: 1 ---- Precision: 0.898 / Recall: 0.797 / Accuracy: 0.959\n",
      "Est: 150 / Depth: 7 / LR: 0.01 ---- Precision: 0.908 / Recall: 0.638 / Accuracy: 0.941\n",
      "Est: 150 / Depth: 7 / LR: 0.1 ---- Precision: 0.91 / Recall: 0.828 / Accuracy: 0.965\n",
      "Est: 150 / Depth: 7 / LR: 1 ---- Precision: 0.885 / Recall: 0.793 / Accuracy: 0.957\n",
      "Est: 150 / Depth: 11 / LR: 0.01 ---- Precision: 0.907 / Recall: 0.716 / Accuracy: 0.95\n",
      "Est: 150 / Depth: 11 / LR: 0.1 ---- Precision: 0.902 / Recall: 0.836 / Accuracy: 0.965\n",
      "Est: 150 / Depth: 11 / LR: 1 ---- Precision: 0.887 / Recall: 0.81 / Accuracy: 0.959\n",
      "Est: 150 / Depth: 15 / LR: 0.01 ---- Precision: 0.918 / Recall: 0.776 / Accuracy: 0.959\n",
      "Est: 150 / Depth: 15 / LR: 0.1 ---- Precision: 0.909 / Recall: 0.819 / Accuracy: 0.964\n",
      "Est: 150 / Depth: 15 / LR: 1 ---- Precision: 0.894 / Recall: 0.832 / Accuracy: 0.963\n"
     ]
    }
   ],
   "source": [
    "for n_est in [50, 100, 150]:\n",
    "    for max_depth in [3, 7, 11, 15]:\n",
    "        for lr in [0.01, 0.1, 1]:\n",
    "            train_GB(n_est, max_depth, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
